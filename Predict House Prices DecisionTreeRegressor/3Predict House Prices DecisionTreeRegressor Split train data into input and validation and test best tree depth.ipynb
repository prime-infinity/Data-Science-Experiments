{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b99e70f1",
   "metadata": {},
   "source": [
    "# overfitting and underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2014a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here, we want to see the best tree depth that would give us the best accuracy, so we aviod overfitting or underfitting\n",
    "#basically, overfitting occurs when there are too many splits in the tree, and with each split, the number of data reduces\n",
    "#with this reduce in the number of data, there is not enough data to train the model and the model therefore captures patterns\n",
    "#in the few data points too well, resulting in a model that fits the training data too well, but does poorly with new validation\n",
    "#data, in contrast, underfitting occurs when the model does not have enough splits, and the datasets therefore the dataset\n",
    "#has too much variations, the model therefore fails to capture patterns in the data set\n",
    "#for more info, check https://www.kaggle.com/code/dansbecker/underfitting-and-overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca684cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78e868fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we load the train dataset\n",
    "house_data_train = pd.read_csv(\"Data/train.csv\")\n",
    "#we then initialise the X and y, recall the X is the features, or the input, and the y is out output\n",
    "house_data_train_features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = house_data_train[house_data_train_features]\n",
    "y = house_data_train.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa79d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2386ffe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([307000., 223500., 145000., ..., 127000.,  89500.,  81000.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#next, we build the model using the train features and output\n",
    "house_model = DecisionTreeRegressor(random_state=1)\n",
    "house_model.fit(X_train,y_train)\n",
    "price_predictions = house_model.predict(X_train)\n",
    "price_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ab38c8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6       307000\n",
       "807     223500\n",
       "955     145000\n",
       "1040    155000\n",
       "701     140000\n",
       "Name: SalePrice, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "81b21c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above was training data, so its no surprise that the values are same, \n",
    "#lets test on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "084cdb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29652.931506849316"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_predictions = house_model.predict(X_test)\n",
    "mean_absolute_error(y_test, real_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4877e6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#approximately $30000, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "49b939ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that we have everything set up, lets see how the tree depth can affect the accuracy of our predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eeaef3",
   "metadata": {},
   "source": [
    "# get_mae function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ca86beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the below function takes in four arguements, the max tree depth we want, the training and validation data for both test\n",
    "#and train, and it outputs the mae while we vary the tree depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "846c61f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, test_X, train_y, test_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    predictions = model.predict(test_X)\n",
    "    mae = mean_absolute_error(test_y, predictions)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8162f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above function should be easy enough for you all to know what's happening, \n",
    "#i highly reccommend taking a programming course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cdebd631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next, we store different leaf nodes in an array and loop over them, everytime calling the get_mae function\n",
    "leaf_nodes = [5, 25, 50, 100, 250, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b93372f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: 35044.51299744237,\n",
       " 25: 29016.41319191076,\n",
       " 50: 27405.930473214907,\n",
       " 100: 27282.50803885739,\n",
       " 250: 27893.822225701646,\n",
       " 500: 29454.18598068598}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#there are different ways to write loops in python, lets use a simple one\n",
    "scores = {}\n",
    "for node in leaf_nodes:\n",
    "    score = get_mae(node, X_train, X_test, y_train, y_test)\n",
    "    scores[node] = score\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "55c7dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just looking at it manually, we can see that the minimum mae comes from using a tree depth of 100\n",
    "#usign a depth of 100 on this particular dataset gives us a mae of approx $27300, our model accuracy increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b4b39c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
